{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_SATD_comments import _Comment, identify_comments, xml_lexer\n",
    "import re\n",
    "from antlr4 import Token, Lexer, InputStream\n",
    "from lexer.CMakeLexer import CMakeLexer\n",
    "from lexer.MakefileCommentLexer import MakefileCommentLexer\n",
    "from lexer.MakefileAmCommentLexer import MakefileAmCommentLexer\n",
    "from lexer.CPP14Lexer import CPP14Lexer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ada987",
   "metadata": {},
   "outputs": [],
   "source": [
    "SATD_comments = pd.read_csv('../data/SATD_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SATD_comments['filePath'] = SATD_comments['linkLocation'].apply(lambda x: ''.join(x.split('#L')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f919ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(content, comments):\n",
    "    i = 0\n",
    "    for comment in comments:\n",
    "        for line in comment.get_text().split('\\n'):\n",
    "            content = content.replace(line, '', 1)\n",
    "    # This is hack to clean undiscoved comment because of Antrl4 cannot read these \"wrong\" grammar\n",
    "    lines = [line if len(line.strip()) == 0 else ('' if line.strip()[0] == '#' else line) for line in content.split('\\n')]\n",
    "    content = '\\n'.join(lines)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippets_list = [pd.Series(), pd.Series(), pd.Series(), pd.Series()]\n",
    "\n",
    "thresholds = [5,10,15,20]\n",
    "\n",
    "for name, group in SATD_comments.groupby('filePath'):\n",
    "    file = '/data/satd-clone-2022/' + str(group.iloc[0]['repoIndex']) + '/' + '/'.join(name.split('/')[7:])\n",
    "    content = open(file, 'r', errors='ignore').read()\n",
    "    input_stream = InputStream(content)\n",
    "    if re.match(r'^build\\.xml$', file.split('/')[-1]) or re.match(r'^(pom\\.xml|maven[123]?\\.xml)$', file.split('/')[-1]):\n",
    "        comments = xml_lexer(file, content)\n",
    "    elif re.match(r'^([Cc]onfigure.in|[Mm]akefile.in)$', file.split('/')[-1]) or re.match(r'^[Cc]onfigure.ac$', file.split('/')[-1]) or re.match(r'^ac(local|site).m4$', file.split('/')[-1]):\n",
    "        comments = identify_comments(MakefileCommentLexer(input_stream))\n",
    "    elif re.match(r'^config.h.in$', file.split('/')[-1]):\n",
    "        comments = identify_comments(CPP14Lexer(input_stream))\n",
    "    elif re.match(r'^[Mm]akefile.am$', file.split('/')[-1]):\n",
    "        comments = identify_comments(MakefileAmCommentLexer(input_stream))\n",
    "    elif re.findall(r'.cmake', file.split('/')[-1]) or file.split('/')[-1] == 'CMakeLists.txt' or file.split('/')[-1] == 'build.properties':\n",
    "        comments = identify_comments(CMakeLexer(input_stream))\n",
    "    else: \n",
    "        print(name)\n",
    "        continue\n",
    "\n",
    "    content = clean_comments(content, comments)\n",
    "    lines = content.split('\\n')\n",
    "    for index, row in group.iterrows():\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            start_line = row['startLine'] - 1\n",
    "            upper_code = []\n",
    "            while start_line > 1 and len(upper_code) < threshold:\n",
    "                code = lines[start_line]\n",
    "                if code.strip() != '': upper_code.append(code)\n",
    "                start_line -= 1\n",
    "            upper_code.reverse()\n",
    "            end_line = row['endLine'] + 1\n",
    "            bottom_code = []\n",
    "            while end_line < len(lines) and len(bottom_code) < threshold:\n",
    "                code = lines[end_line]\n",
    "                if code.strip() != '': bottom_code.append(code)\n",
    "                end_line += 1\n",
    "            code_snippets_list[i].at[index] = '\\n'.join(upper_code + bottom_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, threshold in enumerate(thresholds):\n",
    "    SATD_comments['codeSnippet'+str(threshold)] = code_snippets_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SATD_comments.to_csv('../data/SATD_clones_with_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import math\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import string \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate import bleu_score\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, threshold in enumerate(thresholds):\n",
    "    punctuations = string.punctuation.replace(\"\\\"\",\"\")\n",
    "    SATD_comments_clone_same_system = SATD_comments.loc[SATD_comments['systemDiversity'] == 1].reset_index()\n",
    "    cleand_code_snippets = [code.replace('\\n',' ').strip() for code in list(SATD_comments_clone_same_system['codeSnippet'+str(threshold)])]\n",
    "    cleand_code_snippets = [code.translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations})) for code in cleand_code_snippets]\n",
    "    SATD_comments_clone_same_system['cleaned_code'] = cleand_code_snippets\n",
    "    data_count_vect = CountVectorizer(max_df=0.5)\n",
    "    data_vect = data_count_vect.fit_transform(cleand_code_snippets)\n",
    "    similarity = cosine_similarity(data_vect)    \n",
    "    cos_score_mins = []\n",
    "    cos_score_maxs = []\n",
    "    cos_score_means = []\n",
    "    cos_score_medians = []\n",
    "    systems = []\n",
    "    names = []\n",
    "    for name, group in SATD_comments_clone_same_system.groupby('groupId'):\n",
    "        group_index = list(group.index.values)\n",
    "        names.append(name)\n",
    "        cos_score = []\n",
    "        for combination in itertools.combinations(group_index, 2):\n",
    "            cos_score.append(similarity[combination[0]][combination[1]])\n",
    "        systems.append(group.iloc[0]['buildSysteminFile'])\n",
    "        stat = pd.DataFrame(cos_score)[0].describe()\n",
    "        cos_score_mins.append(stat['min'])\n",
    "        cos_score_maxs.append(stat['max'])\n",
    "        cos_score_means.append(stat['mean'])\n",
    "        cos_score_medians.append(stat['50%'])\n",
    "    stat_df = pd.DataFrame({'min': cos_score_mins,\n",
    "             'max': cos_score_maxs,\n",
    "             'mean': cos_score_means,\n",
    "             'median': cos_score_medians,\n",
    "            'system': systems,\n",
    "            'groupId': names})\n",
    "    stat_df.to_csv(\"../data/RQ2_SATD_stat_{}.csv\".format(str(threshold)),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172818d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cc92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satd-clone",
   "language": "python",
   "name": "satd-clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
