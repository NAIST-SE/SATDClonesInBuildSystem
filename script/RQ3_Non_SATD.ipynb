{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Non_SATD_comments = pd.read_csv('../data/Non_SATD_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments['filePath'] = Non_SATD_comments['linkLocation'].apply(lambda x: ''.join(x.split('#L')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea69766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "import dask\n",
    "import multiprocessing\n",
    "import os\n",
    "# dask.config.set(scheduler='multiprocessing')\n",
    "# get num cpu cores\n",
    "num_partitions = multiprocessing.cpu_count()\n",
    "\n",
    "def git_log(row):\n",
    "    fname = '/'.join(row['filePath'].split('/')[7:])\n",
    "    cmd = 'cd {path}; git log --pretty=format:%H^^^^%an^^^^%ae^^^^%at^^^^%B --no-patch -L {lnumber},{lnumber}:\"{fname}\"'.format(\n",
    "        path = \"/data/satd-clone-2022/\" + str(row['repoIndex']),\n",
    "        lnumber=row['startLine'],\n",
    "        fname=fname)\n",
    "    with os.popen(cmd) as process:\n",
    "        result = process.read()\n",
    "    result = str(row.name) + '^^^^' + result\n",
    "    return result\n",
    "df_dask = ddf.from_pandas(Non_SATD_comments, npartitions=(num_partitions-1)*4)\n",
    "df_dask['output'] = df_dask.apply(lambda x: git_log(x), meta=('str'), axis=1).compute(scheduler='multiprocessing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15895268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['introducedSha'] = df['output'].apply(lambda x: x.split('^^^^')[1])\n",
    "df['authorName'] = df['output'].apply(lambda x: x.split('^^^^')[2])\n",
    "df['authorEmail'] = df['output'].apply(lambda x: x.split('^^^^')[3])\n",
    "df['authorTime'] = df['output'].apply(lambda x: x.split('^^^^')[4])\n",
    "df['commitMessage'] = df['output'].apply(lambda x: x.split('^^^^')[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56bbdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments.to_csv('../data/Non_SATD_clones_with_authorship.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09030e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments_external_repository = Non_SATD_comments.loc[Non_SATD_comments['repoDiversity'] != 1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import string\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "def clean_url(text):\n",
    "    text = ''.join([word if word not in string.punctuation else ' ' for word in text.group(0)])\n",
    "    return text\n",
    "\n",
    "def clean_string(text):\n",
    "    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)',clean_url, text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    if len(re.findall(r'\\bdnl\\b', text)) > 0:\n",
    "        lines = []\n",
    "        for line in text.split('\\n'):\n",
    "            if len(line.split()) > 0:\n",
    "                if 'dnl' == line.split()[0]:\n",
    "                    line = line.replace('dnl', '', 1)\n",
    "            lines.append(line)\n",
    "        text ='\\n'.join(lines)\n",
    "    text = re.sub(r'[^A-Za-z0-9.\\']+',' ',text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cleaned_message = [clean_string(message) for message in list(Non_SATD_comments_external_repository['commitMessage'])]\n",
    "mesage_embeddings = model.encode(cleaned_message)\n",
    "csim_message = cosine_similarity(mesage_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_diversity = []\n",
    "author_max_clone_diversity = []\n",
    "author_clone_interval = []\n",
    "cos_score_mins_message = []\n",
    "cos_score_maxs_message = []\n",
    "cos_score_means_message = []\n",
    "cos_score_medians_message = []\n",
    "names = []\n",
    "is_same_author = []\n",
    "same_sha = []\n",
    "for name, group in Non_SATD_comments_external_repository.groupby('groupId'):\n",
    "#     print(group)\n",
    "    same_sha.append(len(list(group['introducedSha'].unique())) / group.shape[0])\n",
    "    group = group.drop_duplicates(subset=['introducedSha','repoName'], keep='last')\n",
    "    if group.shape[0] == 1:\n",
    "        continue\n",
    "    if group.groupby([\"authorName\", \"authorEmail\"]).size().reset_index(name=\"Time\").shape[0] > 1:\n",
    "        is_same_author.append(0)\n",
    "    else:\n",
    "        is_same_author.append(1)\n",
    "    group_index = list(group.index.values)\n",
    "    names.append(name)\n",
    "    author_fre = group.groupby([\"authorName\", \"authorEmail\"]).size().reset_index(name=\"Time\")\n",
    "    author_max_clone_diversity.append(max(list(author_fre['Time'])) / group.shape[0])\n",
    "    author_diversity.append(author_fre.shape[0] / group.shape[0])\n",
    "    times = group['authorTime'].apply(lambda x: datetime.datetime.fromtimestamp(int(x)))\n",
    "    author_clone_interval.append((max(times) - min(times))/ datetime.timedelta(days=1))\n",
    "    cos_score = []\n",
    "    for combination in itertools.combinations(group_index, 2):\n",
    "        cos_score.append(csim_message[combination[0]][combination[1]])\n",
    "    \n",
    "    stat = pd.DataFrame(cos_score)[0].describe()\n",
    "    cos_score_mins_message.append(stat['min'])\n",
    "    cos_score_maxs_message.append(stat['max'])\n",
    "    cos_score_means_message.append(stat['mean'])\n",
    "    cos_score_medians_message.append(stat['50%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(is_same_author, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat = pd.DataFrame({'min': cos_score_mins_message,\n",
    "             'max': cos_score_maxs_message,\n",
    "             'mean': cos_score_means_message,\n",
    "             'median': cos_score_medians_message,\n",
    "            'author_clone_interval': author_clone_interval,\n",
    "            'author_max_clone_diversity': author_max_clone_diversity,\n",
    "            'author_diversity': author_diversity,\n",
    "            'same_sha': same_sha,\n",
    "            'groupId': names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stat.to_csv(\"../data/RQ3_Non_SATD_stat.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd65993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
