{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_SATD_comments import _Comment, identify_comments, xml_lexer\n",
    "import re\n",
    "from antlr4 import Token, Lexer, InputStream\n",
    "from lexer.CMakeLexer import CMakeLexer\n",
    "from lexer.MakefileCommentLexer import MakefileCommentLexer\n",
    "from lexer.MakefileAmCommentLexer import MakefileAmCommentLexer\n",
    "from lexer.CPP14Lexer import CPP14Lexer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments = pd.read_csv('../data/Non_SATD_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(content, comments):\n",
    "    for comment in comments:\n",
    "        for line in comment.text.split('\\n'):\n",
    "            content = content.replace(line, '', 1)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(content, comments):\n",
    "    i = 0\n",
    "    for comment in comments:\n",
    "        for line in comment.get_text().split('\\n'):\n",
    "            content = content.replace(line, '', 1)\n",
    "    # This is hack to clean undiscoved comment because of Antrl4 cannot read these \"wrong\" grammar\n",
    "    lines = [line if len(line.strip()) == 0 else ('' if line.strip()[0] == '#' else line) for line in content.split('\\n')]\n",
    "    content = '\\n'.join(lines)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_snippets = pd.Series()\n",
    "threshold = 5\n",
    "\n",
    "for name, group in Non_SATD_comments.groupby('filePath'):\n",
    "    file = '/data/satd-clone-2022/' + str(group.iloc[0]['repoIndex']) + '/' + '/'.join(name.split('/')[7:])\n",
    "\n",
    "    content = open(file, 'r', errors='ignore').read()\n",
    "    input_stream = InputStream(content)\n",
    "    if re.match(r'^build\\.xml$', file.split('/')[-1]) or re.match(r'^(pom\\.xml|maven[123]?\\.xml)$', file.split('/')[-1]):\n",
    "        comments = xml_lexer(file, content)\n",
    "    elif re.match(r'^([Cc]onfigure.in|[Mm]akefile.in)$', file.split('/')[-1]) or re.match(r'^[Cc]onfigure.ac$', file.split('/')[-1]) or re.match(r'^ac(local|site).m4$', file.split('/')[-1]):\n",
    "        comments = identify_comments(MakefileCommentLexer(input_stream))\n",
    "    elif re.match(r'^config.h.in$', file.split('/')[-1]):\n",
    "        comments = identify_comments(CPP14Lexer(input_stream))\n",
    "    elif re.match(r'^[Mm]akefile.am$', file.split('/')[-1]):\n",
    "        comments = identify_comments(MakefileAmCommentLexer(input_stream))\n",
    "    elif re.findall(r'.cmake', file.split('/')[-1]) or file.split('/')[-1] == 'CMakeLists.txt' or file.split('/')[-1] == 'build.properties':\n",
    "        comments = identify_comments(CMakeLexer(input_stream))\n",
    "    else: \n",
    "        print(name)\n",
    "        continue\n",
    "\n",
    "    content = clean_comments(content, comments)\n",
    "\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    for index, row in group.iterrows():\n",
    "        start_line = row['startLine']\n",
    "        upper_code = []\n",
    "        while start_line >= 1 and len(upper_code) < threshold:\n",
    "            code = lines[start_line - 1]\n",
    "            if code.strip() != '': upper_code.append(code)\n",
    "            start_line -= 1\n",
    "        upper_code.reverse()\n",
    "\n",
    "        end_line = row['endLine']\n",
    "        bottom_code = []\n",
    "        while end_line <= len(lines) and len(bottom_code) < threshold:\n",
    "            code = lines[end_line - 1]\n",
    "            if code.strip() != '': bottom_code.append(code)\n",
    "            end_line += 1\n",
    "        code_snippets.at[index] = '\\n'.join(upper_code + bottom_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments['codeSnippet'] = code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e40eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments.to_csv('../data/Non_SATD_clones_with_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import math\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import string \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate import bleu_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_SATD_comments_clone_same_system = Non_SATD_comments.loc[Non_SATD_comments['systemDiversity'] == 1].reset_index()\n",
    "punctuations = string.punctuation.replace(\"\\\"\",\"\")\n",
    "cleand_code_snippets = [code.replace('\\n',' ').strip() for code in list(Non_SATD_comments_clone_same_system['codeSnippet'])]\n",
    "cleand_code_snippets = [code.translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations})) for code in cleand_code_snippets]\n",
    "Non_SATD_comments_clone_same_system['cleaned_code'] = cleand_code_snippets\n",
    "data_count_vect = CountVectorizer(max_df=0.5)\n",
    "data_vect = data_count_vect.fit_transform(cleand_code_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(data_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "cos_score_mins = []\n",
    "cos_score_maxs = []\n",
    "cos_score_means = []\n",
    "cos_score_medians = []\n",
    "systems = []\n",
    "names = []\n",
    "for name, group in Non_SATD_comments_clone_same_system.groupby('groupId'):\n",
    "    group_index = list(group.index.values)\n",
    "    cos_score = []\n",
    "    names.append(name)\n",
    "    for combination in itertools.combinations(group_index, 2):\n",
    "        cos_score.append(similarity[combination[0]][combination[1]])\n",
    "    systems.append(group.iloc[0]['buildSysteminFile'])\n",
    "    stat = pd.DataFrame(cos_score)[0].describe()\n",
    "    cos_score_mins.append(stat['min'])\n",
    "    cos_score_maxs.append(stat['max'])\n",
    "    cos_score_means.append(stat['mean'])\n",
    "    cos_score_medians.append(stat['50%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d263a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = pd.DataFrame({'min': cos_score_mins,\n",
    "             'max': cos_score_maxs,\n",
    "             'mean': cos_score_means,\n",
    "             'median': cos_score_medians,\n",
    "            'system': systems,\n",
    "            'groupId': names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.to_csv(\"../data/RQ2_Non_SATD_stat.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c709b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
